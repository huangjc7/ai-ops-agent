package model

import (
	"ai-ops-agent/pkg/tools"
	"context"
	"fmt"
	openai "github.com/sashabaranov/go-openai"
)

// æœ€å¤§å¯¹è¯å†å²é•¿åº¦ï¼Œé˜²æ­¢ Token è¶…é™
const maxHistory = 5

var ChatHistory []openai.ChatCompletionMessage

type ConfigClient struct {
	ApiKey  string
	BaseURL string
	Model   string
}

type HunYuan struct {
	client *openai.Client
	model  string
}

type Sender interface {
	SupportSend()
	Send()
}

// NewAIClient åˆ›å»º HunYuan AI å®¢æˆ·ç«¯
func NewAIClient(cfg *ConfigClient) Sender {
	config := openai.DefaultConfig(cfg.ApiKey)
	config.BaseURL = cfg.BaseURL
	client := openai.NewClientWithConfig(config)

	return &HunYuan{client: client, model: cfg.Model}
}

// ChatHistory æ™ºèƒ½è£å‰ªå¯¹è¯å†å²ï¼Œé˜²æ­¢ Token è¶…é™
func trimChatHistory(history []openai.ChatCompletionMessage) []openai.ChatCompletionMessage {
	maxAssistantCount := maxHistory
	// ç»Ÿè®¡ Role=assistant çš„æ€»æ•°é‡
	assistantCount := 0
	for _, msg := range history {
		if msg.Role == openai.ChatMessageRoleAssistant {
			assistantCount++
		}
	}

	// å¦‚æœæ€»æ•°å°äºç­‰äº maxAssistantCountï¼Œç›´æ¥è¿”å›åŸå§‹å†å²ï¼Œä¸éœ€è¦è£å‰ª
	if assistantCount <= maxAssistantCount {
		fmt.Printf("å½“å‰ Role=assistant æ¶ˆæ¯æ•°: %dï¼Œå°äºæˆ–ç­‰äº %dï¼Œæ— éœ€è£å‰ªã€‚\n", assistantCount, maxAssistantCount)
		return history
	}

	fmt.Printf("å½“å‰ Role=assistant æ¶ˆæ¯æ•°: %dï¼Œè¶…è¿‡ %dï¼Œå¼€å§‹è£å‰ª...\n", assistantCount, maxAssistantCount)

	// å¦‚æœéœ€è¦è£å‰ªï¼Œåˆ™å¼€å§‹ä¿ç•™æœ€æ–°çš„ maxAssistantCount æ¡
	var trimmedHistory []openai.ChatCompletionMessage
	var assistantHistory []openai.ChatCompletionMessage

	// ä»åå¾€å‰æ‰¾åˆ°æœ€æ–°çš„ maxAssistantCount ä¸ª Role=assistant çš„è®°å½•
	for i := len(history) - 1; i >= 0; i-- {
		if history[i].Role == openai.ChatMessageRoleAssistant {
			assistantHistory = append([]openai.ChatCompletionMessage{history[i]}, assistantHistory...)
			if len(assistantHistory) >= maxAssistantCount {
				break
			}
		}
	}

	// å†æ¬¡éå†åˆ‡ç‰‡ï¼Œä¿ç•™éRole=assistantçš„è®°å½•ï¼Œä»¥åŠæœ€æ–°çš„ assistantHistory
	for _, msg := range history {
		if msg.Role != openai.ChatMessageRoleAssistant {
			trimmedHistory = append(trimmedHistory, msg)
		}
	}

	// åˆå¹¶ä¿ç•™çš„éRole=assistantè®°å½•å’Œæœ€æ–°çš„maxAssistantCountä¸ªRole=assistantè®°å½•
	trimmedHistory = append(trimmedHistory, assistantHistory...)

	fmt.Printf("è£å‰ªå®Œæˆï¼Œå½“å‰å†å²è®°å½•æ€»æ•°: %dï¼Œå…¶ä¸­ Role=assistant: %d\n", len(trimmedHistory), maxAssistantCount)

	return trimmedHistory
}

// Send æä¾›åŸºæœ¬å¯¹è¯èƒ½åŠ›
func (hy *HunYuan) Send() {

	//è£å‰ªå¯¹è¯å†å²
	//ChatHistory = trimChatHistory(ChatHistory)

	// å‘é€è¯·æ±‚ï¼Œä½¿ç”¨ Tools
	resp, err := hy.client.CreateChatCompletion(context.Background(), openai.ChatCompletionRequest{
		Model:    hy.model,
		Messages: ChatHistory,
	})
	if err != nil {
		fmt.Println("âŒ è¯·æ±‚ AI å¤±è´¥:", err)
	}

	// å¦‚æœ AI æ²¡æœ‰è°ƒç”¨ Functionï¼Œç›´æ¥è¿”å›å›ç­”
	aiReply := resp.Choices[0].Message.Content
	// è¿½åŠ  AI å›å¤åˆ°å†å²å¯¹è¯
	ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
		Role:    openai.ChatMessageRoleAssistant,
		Content: aiReply,
	})

}

// SupportSend æä¾›ä¿®å¤èƒ½åŠ›
func (hy *HunYuan) SupportSend() {

	// å‘é€è¯·æ±‚ï¼Œä½¿ç”¨ Tools
	resp, err := hy.client.CreateChatCompletion(context.Background(), openai.ChatCompletionRequest{
		Model:      hy.model,
		Messages:   ChatHistory,
		Tools:      availableTools,
		ToolChoice: nil, // âœ… è®© AI è‡ªåŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
	})
	if err != nil {
		fmt.Println("âŒ è¯·æ±‚ AI å¤±è´¥:", err)
	}

	// æ£€æŸ¥ AI æ˜¯å¦è°ƒç”¨äº† Tool
	if len(resp.Choices) > 0 {
		if len(resp.Choices[0].Message.ToolCalls) > 0 {
			fmt.Println("ğŸ”§ AI éœ€è¦è°ƒç”¨ Tool:", resp.Choices[0].Message.ToolCalls[0].Function.Name)

			// è§£æ Tool å‚æ•°
			//var params json.RawMessage = []byte(resp.Choices[0].Message.ToolCalls[0].Function.Arguments)

			// æ‰§è¡Œå¯¹åº”çš„ Toolï¼ˆFunctionï¼‰
			var functionResult string
			switch resp.Choices[0].Message.ToolCalls[0].Function.Name {
			case "FixDockerService":
				result, err := tools.FixDockerService()
				if err != nil {
					fmt.Println("âŒ Tool æ‰§è¡Œå¤±è´¥:", err)
					return
				}
				functionResult = result
			case "FixDiskIssue":
				result, err := tools.FixDiskIssue()
				if err != nil {
					fmt.Println("âŒ Tool æ‰§è¡Œå¤±è´¥:", err)
					return
				}
				functionResult = result
			case "GetTopMemoryProcesses":
				result, err := tools.GetTopMemoryProcesses()
				if err != nil {
					fmt.Println("âŒ Tool æ‰§è¡Œå¤±è´¥:", err)
					return
				}
				functionResult = result
			case "GetTopCpuProcesses":
				result, err := tools.GetTopCpuProcesses()
				if err != nil {
					fmt.Println("âŒ Tool æ‰§è¡Œå¤±è´¥:", err)
					return
				}
				functionResult = result
			}

			// è¿”å› Function ç»“æœç»™ AI
			ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleTool,
				Content: functionResult,
			})

			// ç¡®ä¿ chatHistory ä»¥ assistant è§’è‰²ç»“æŸ
			ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleAssistant,
				Content: fmt.Sprintf("ç»“æœï¼š%s", functionResult),
			})
		} else {
			// å¦‚æœ AI æ²¡æœ‰è°ƒç”¨ Functionï¼Œç›´æ¥è¿”å›å›ç­”
			aiReply := resp.Choices[0].Message.Content
			// è¿½åŠ  AI å›å¤åˆ°å†å²å¯¹è¯
			ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleAssistant,
				Content: aiReply,
			})
		}
	}
}
