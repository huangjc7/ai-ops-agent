package model

import (
	"context"
	"encoding/json"
	"fmt"
	openai "github.com/sashabaranov/go-openai"
	"os/exec"
)

// æœ€å¤§å¯¹è¯å†å²é•¿åº¦ï¼Œé˜²æ­¢ Token è¶…é™
const maxHistory = 5

var ChatHistory []openai.ChatCompletionMessage

// æ”¯æŒçš„å·¥å…·ï¼ˆToolsï¼Œæ›¿ä»£ Functionsï¼‰
var availableTools = []openai.Tool{
	{
		Type: openai.ToolTypeFunction,
		Function: &openai.FunctionDefinition{
			Name:        "fixDiskIssue",
			Description: "ç”¨äºåœ¨æ£€æµ‹åˆ°ç£ç›˜é—®é¢˜æ—¶æ‰§è¡Œä¿®å¤æˆ–æ¸…ç†æ“ä½œã€‚ä»…åœ¨æ˜ç¡®æç¤ºç£ç›˜ç›¸å…³é”™è¯¯çš„æƒ…å†µä¸‹ä½¿ç”¨",
			Parameters:  map[string]interface{}{},
		},
	},
	{
		Type: openai.ToolTypeFunction,
		Function: &openai.FunctionDefinition{
			Name:        "fixDockerService",
			Description: "ç”¨äºDockeræœåŠ¡åœæ­¢æˆ–å¼‚å¸¸æ—¶æ‰§è¡Œä¿®å¤æ“ä½œï¼Œä»…åœ¨æ˜ç¡®æç¤ºDockerç›¸å…³é”™è¯¯çš„æƒ…å†µä¸‹ä½¿ç”¨",
			Parameters:  map[string]interface{}{},
		},
	},
}

type ConfigClient struct {
	ApiKey  string
	BaseURL string
	Model   string
}

type HunYuan struct {
	client *openai.Client
	model  string
}

type Sender interface {
	SupportSend()
	Send()
}

// NewAIClient åˆ›å»º HunYuan AI å®¢æˆ·ç«¯
func NewAIClient(cfg *ConfigClient) Sender {
	config := openai.DefaultConfig(cfg.ApiKey)
	config.BaseURL = cfg.BaseURL
	client := openai.NewClientWithConfig(config)

	return &HunYuan{client: client, model: cfg.Model}
}

// æ™ºèƒ½è£å‰ªå¯¹è¯å†å²ï¼Œé˜²æ­¢ Token è¶…é™
func trimChatHistory(history []openai.ChatCompletionMessage) []openai.ChatCompletionMessage {
	maxAssistantCount := maxHistory
	// ç»Ÿè®¡ Role=assistant çš„æ€»æ•°é‡
	assistantCount := 0
	for _, msg := range history {
		if msg.Role == openai.ChatMessageRoleAssistant {
			assistantCount++
		}
	}

	// å¦‚æœæ€»æ•°å°äºç­‰äº maxAssistantCountï¼Œç›´æ¥è¿”å›åŸå§‹å†å²ï¼Œä¸éœ€è¦è£å‰ª
	if assistantCount <= maxAssistantCount {
		fmt.Printf("å½“å‰ Role=assistant æ¶ˆæ¯æ•°: %dï¼Œå°äºæˆ–ç­‰äº %dï¼Œæ— éœ€è£å‰ªã€‚\n", assistantCount, maxAssistantCount)
		return history
	}

	fmt.Printf("å½“å‰ Role=assistant æ¶ˆæ¯æ•°: %dï¼Œè¶…è¿‡ %dï¼Œå¼€å§‹è£å‰ª...\n", assistantCount, maxAssistantCount)

	// å¦‚æœéœ€è¦è£å‰ªï¼Œåˆ™å¼€å§‹ä¿ç•™æœ€æ–°çš„ maxAssistantCount æ¡
	var trimmedHistory []openai.ChatCompletionMessage
	var assistantHistory []openai.ChatCompletionMessage

	// ä»åå¾€å‰æ‰¾åˆ°æœ€æ–°çš„ maxAssistantCount ä¸ª Role=assistant çš„è®°å½•
	for i := len(history) - 1; i >= 0; i-- {
		if history[i].Role == openai.ChatMessageRoleAssistant {
			assistantHistory = append([]openai.ChatCompletionMessage{history[i]}, assistantHistory...)
			if len(assistantHistory) >= maxAssistantCount {
				break
			}
		}
	}

	// å†æ¬¡éå†åˆ‡ç‰‡ï¼Œä¿ç•™éRole=assistantçš„è®°å½•ï¼Œä»¥åŠæœ€æ–°çš„ assistantHistory
	for _, msg := range history {
		if msg.Role != openai.ChatMessageRoleAssistant {
			trimmedHistory = append(trimmedHistory, msg)
		}
	}

	// åˆå¹¶ä¿ç•™çš„éRole=assistantè®°å½•å’Œæœ€æ–°çš„maxAssistantCountä¸ªRole=assistantè®°å½•
	trimmedHistory = append(trimmedHistory, assistantHistory...)

	fmt.Printf("è£å‰ªå®Œæˆï¼Œå½“å‰å†å²è®°å½•æ€»æ•°: %dï¼Œå…¶ä¸­ Role=assistant: %d\n", len(trimmedHistory), maxAssistantCount)

	return trimmedHistory
}

// æ¨¡æ‹ŸæœåŠ¡å™¨å·¡æ£€
func fixDockerService(args json.RawMessage) (string, error) {

	err := exec.Command("systemctl", "start", "docker").Run()
	systemStatus := map[string]string{
		"status_name": "Docker",
		"status":      "å·²ä¿®å¤",
	}
	if err != nil {
		systemStatus = map[string]string{
			"status_name": "Docker",
			"status":      "å¯åŠ¨å¤±è´¥",
		}

	}
	// è½¬æ¢ä¸º JSON
	statusJSON, _ := json.Marshal(systemStatus)
	return string(statusJSON), nil
}

// æ¨¡æ‹Ÿé—®é¢˜ä¿®å¤ï¼ˆä»…æ¸…ç†ç£ç›˜ï¼Œä¸æ‰§è¡Œå…¶ä»–æ“ä½œï¼‰
func fixDiskIssue(args json.RawMessage) (string, error) {

	// çœŸæ­£æ‰§è¡Œé€»è¾‘
	cmd := exec.Command("find", "/", "-type", "f", "-size", "+1G", "-name", "*log*", "-exec", "bash", "-c", "> {}", ";")
	err := cmd.Run()

	// æ¨¡æ‹Ÿæ—¥å¿—è¾“å‡º
	fixResult := map[string]string{
		"action":  "æ¸…ç†ç£ç›˜",
		"result":  "å·²é‡Šæ”¾ 10GB ç©ºé—´",
		"success": "true",
	}
	if err != nil {
		fixResult = map[string]string{
			"action":  "æ¸…ç†ç£ç›˜",
			"result":  "æ¸…ç†ç£ç›˜å¤±è´¥",
			"success": "false",
		}
	}
	resultJSON, _ := json.Marshal(fixResult)

	return string(resultJSON), nil
}

// Send å‘é€ç”¨æˆ·è¯·æ±‚
func (hy *HunYuan) Send() {

	//è£å‰ªå¯¹è¯å†å²
	//ChatHistory = trimChatHistory(ChatHistory)

	// å‘é€è¯·æ±‚ï¼Œä½¿ç”¨ Tools
	resp, err := hy.client.CreateChatCompletion(context.Background(), openai.ChatCompletionRequest{
		Model:    hy.model,
		Messages: ChatHistory,
	})
	if err != nil {
		fmt.Println("âŒ è¯·æ±‚ AI å¤±è´¥:", err)
	}

	// å¦‚æœ AI æ²¡æœ‰è°ƒç”¨ Functionï¼Œç›´æ¥è¿”å›å›ç­”
	aiReply := resp.Choices[0].Message.Content
	// è¿½åŠ  AI å›å¤åˆ°å†å²å¯¹è¯
	ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
		Role:    openai.ChatMessageRoleAssistant,
		Content: aiReply,
	})

}

func (hy *HunYuan) SupportSend() {

	// å‘é€è¯·æ±‚ï¼Œä½¿ç”¨ Tools
	resp, err := hy.client.CreateChatCompletion(context.Background(), openai.ChatCompletionRequest{
		Model:      hy.model,
		Messages:   ChatHistory,
		Tools:      availableTools,
		ToolChoice: nil, // âœ… è®© AI è‡ªåŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
	})
	if err != nil {
		fmt.Println("âŒ è¯·æ±‚ AI å¤±è´¥:", err)
	}

	// æ£€æŸ¥ AI æ˜¯å¦è°ƒç”¨äº† Tool
	if len(resp.Choices) > 0 {
		if len(resp.Choices[0].Message.ToolCalls) > 0 {
			fmt.Println("ğŸ”§ AI éœ€è¦è°ƒç”¨ Tool:", resp.Choices[0].Message.ToolCalls[0].Function.Name)

			// è§£æ Tool å‚æ•°
			var params json.RawMessage = []byte(resp.Choices[0].Message.ToolCalls[0].Function.Arguments)

			// æ‰§è¡Œå¯¹åº”çš„ Toolï¼ˆFunctionï¼‰
			var functionResult string
			switch resp.Choices[0].Message.ToolCalls[0].Function.Name {
			case "fixDockerService":
				result, err := fixDockerService(params)
				if err != nil {
					fmt.Println("âŒ Tool æ‰§è¡Œå¤±è´¥:", err)
					return
				}
				functionResult = result
			case "fixDiskIssue":
				result, err := fixDiskIssue(params)
				if err != nil {
					fmt.Println("âŒ Tool æ‰§è¡Œå¤±è´¥:", err)
					return
				}
				functionResult = result
			}

			// è¿”å› Function ç»“æœç»™ AI
			ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleTool,
				Content: functionResult,
			})

			// ç¡®ä¿ chatHistory ä»¥ assistant è§’è‰²ç»“æŸ
			ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleAssistant,
				Content: fmt.Sprintf("ç»“æœï¼š%s", functionResult),
			})
		} else {
			// å¦‚æœ AI æ²¡æœ‰è°ƒç”¨ Functionï¼Œç›´æ¥è¿”å›å›ç­”
			aiReply := resp.Choices[0].Message.Content
			// è¿½åŠ  AI å›å¤åˆ°å†å²å¯¹è¯
			ChatHistory = append(ChatHistory, openai.ChatCompletionMessage{
				Role:    openai.ChatMessageRoleAssistant,
				Content: aiReply,
			})
		}
	}
}
